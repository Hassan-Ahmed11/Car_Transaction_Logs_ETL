
# Car Transaction Logs ETL Project

This project implements a data pipeline for real-time car transaction logs using **Flask**, **Kafka**, **Apache Flume**, **HDFS**, **Spark**, **InfluxDB**, and **Grafana**. The goal is to stream car transaction data, process it in real-time, store it, and visualize it for analytical insights.

## Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Setup and Configuration](#setup-and-configuration)
4. [Components](#components)
5. [Data Flow](#data-flow)
6. [Usage](#usage)
7. [Visualization](#visualization)
8. [Future Enhancements](#future-enhancements)
9. [License](#license)

## Overview

This project simulates car transaction logs generated by a web server and processes the logs through a real-time ETL (Extract, Transform, Load) pipeline. The processed data is stored in both **HDFS** and **InfluxDB** for analytical and monitoring purposes, with visualizations in **Grafana**.

## Architecture

![Architecture](./image.png)

### Components
- **Flask**: API service to simulate car transaction log generation and expose it as an endpoint.
- **Apache Kafka**: Message broker to handle streaming data in real-time.
- **Apache Flume**: Ingests logs from Kafka and stores them in HDFS.
- **HDFS**: Distributed storage for batch processing and data lake functionality.
- **Apache Spark**: Real-time data processing and analysis.
- **InfluxDB**: Time-series database for storing transaction data for monitoring.
- **Grafana**: Visualization platform for monitoring and analyzing transaction data.

## Setup and Configuration

### Prerequisites
- Python 3.x
- Kafka and Zookeeper
- Apache Flume
- Hadoop (HDFS)
- Apache Spark
- InfluxDB and Grafana

### Installation Steps
1. Clone the repository.
    ```bash
    git clone https://github.com/username/Car_Transaction_Logs_ETL.git
    ```
2. Set up the Python environment.
    ```bash
    pip install -r requirements.txt
    ```
3. Configure Kafka, Zookeeper, Flume, and HDFS as per the configuration files provided.

4. Configure InfluxDB and Grafana:
   - Create a bucket in InfluxDB for the ETL project data.
   - Set up a Grafana dashboard to connect to InfluxDB.

5. Run the Flask server:
    ```bash
    python app.py
    ```

### Kafka & Flume Configuration
- **Kafka Topic**: `car-transactions-logs`
- **Flume Configuration**: (`flume.conf` file)
  - Kafka Source to HDFS Sink.
  - Set the HDFS path to `hdfs://localhost:9000/Cars`.

### Spark Configuration
Set up the `pyspark` script to consume Kafka data and store it in InfluxDB.

## Data Flow

1. **Data Generation**: Flask API simulates car transaction data and sends it to Kafka.
2. **Message Brokering**: Kafka brokers the data stream to Apache Flume.
3. **Storage**:
   - Flume stores the data in HDFS for batch analysis.
   - Spark processes the data in real-time and sends it to InfluxDB.
4. **Visualization**: Grafana accesses data from InfluxDB for monitoring and visualization.

## Usage

### Flask API
The Flask API has two main endpoints:
- `GET /api/stream_car_transactions`: Streams car transaction logs.
- `POST /api/logs`: Receives a log message and sends it to Kafka.

### Spark Streaming to InfluxDB
Run the Spark script to process logs from Kafka and write the transformed data to InfluxDB.

```bash
spark-submit kafka_to_influxdb.py
```

### Viewing Data in Grafana
1. Log into Grafana.
2. Add InfluxDB as a data source.
3. Import or create a dashboard to visualize the car transaction metrics.

## Visualization

**Grafana Dashboard**: Visualizes car transaction data, providing insights into metrics like transaction count, average price, distribution by brand, etc.

## Future Enhancements

- **Fault Tolerance**: Implement data replication and error-handling for each component.
- **Data Enrichment**: Integrate with external APIs for enhanced analytics (e.g., vehicle history reports).
- **Advanced Analytics**: Use Spark MLlib for predictive analytics, such as predicting transaction trends.
- **Scalability**: Deploy the pipeline on a cloud platform to handle larger data volumes.

## License

This project is licensed under the MIT License.
